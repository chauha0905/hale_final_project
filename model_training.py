# -*- coding: utf-8 -*-
"""FP_ds28Dec(+Ha).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12FPFec3F7bRZSNlwb0lzEDwcgAqA_uyB

# FINAL PROJECT _ SITTING POSTURE DETECTION

### Import libraries
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# Import Libraries
import cv2, numpy as np, pandas as pd, pickle, csv
import warnings
warnings.filterwarnings('ignore')
import pathlib, glob, PIL, seaborn as sns, os, matplotlib.pyplot as plt, matplotlib.image as mpimg
# %matplotlib inline
sns.set_style("whitegrid")
from PIL import UnidentifiedImageError, Image
from pathlib import Path
from google.colab import files

#sklearn library
from sklearn.metrics import confusion_matrix, accuracy_score, log_loss, classification_report, plot_confusion_matrix
from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

!pip install mediapipe

# Initializing mediapipe pose class.
import mediapipe as mp
mp_pose     = mp.solutions.pose
pose        = mp_pose.Pose(static_image_mode=True,
                           min_detection_confidence=0.5, 
                           min_tracking_confidence=0.5)     # Setting up the Pose function.
mp_drawing  = mp.solutions.drawing_utils                    # Initializing mediapipe drawing class, useful for annotation.

"""### Load dataset _ CSV

- Dataset has 2 class:
    * ```GOOD```: correct sitting posture 
    * ```POOR```: incorrect sitting posture
"""

# DATASET 01 
good_01 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/correct/CORRECT_45.csv')
good_02 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/correct/CORRECT_FRONT.csv')
good_03 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/correct/CORRECT_NOTAB.csv')
good_04 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/correct/CORRECT_SIDE.csv')

# DATASET 02 - ADDING MORE DATA
a = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/ha_csv/CORRECT_35_LEFT_CLOSE.csv')
b = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/ha_csv/CORRECT_35_RIGHT_FAR.csv')
c = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/ha_csv/CORRECT_45_LEFT_CLOSE.csv')
d = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/ha_csv/CORRECT_45_RIGHT_FAR.csv')
e = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/ha_csv/CORRECT_50_RIGHT_FAR.csv')
good_05 = pd.concat([a,b,c,d,e])

good = pd.concat([good_01, good_02, good_03, good_04, good_05])

# RENAME COLUMNS
good.columns = ['Picture', 'Label',
                  'LEFT_SHOULDER_x','LEFT_SHOULDER_y','LEFT_SHOULDER_z',
                  'RIGHT_SHOULDER_x','RIGHT_SHOULDER_y','RIGHT_SHOULDER_z',
                  'LEFT_ELBOW_x','LEFT_ELBOW_y','LEFT_ELBOW_z',
                  'RIGHT_ELBOW_x','RIGHT_ELBOW_y','RIGHT_ELBOW_z',
                  'LEFT_WRIST_x','LEFT_WRIST_y','LEFT_WRIST_z',
                  'RIGHT_WRIST_x','RIGHT_WRIST_y','RIGHT_WRIST_z',
                  'LEFT_HIP_x','LEFT_HIP_y','LEFT_HIP_z',
                  'RIGHT_HIP_x','RIGHT_HIP_y','RIGHT_HIP_z',
                  'LEFT_KNEE_x','LEFT_KNEE_y','LEFT_KNEE_z',
                  'RIGHT_KNEE_x','RIGHT_KNEE_y','RIGHT_KNEE_z',
                  'LEFT_ANKLE_x','LEFT_ANKLE_y','LEFT_ANKLE_z',
                  'RIGHT_ANKLE_x','RIGHT_ANKLE_y','RIGHT_ANKLE_z']

poor_t1 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/incorrect/INCORRECT_60.csv')
poor_t2 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/incorrect/INCORRECT_LEG.csv')
poor_t3 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/incorrect/INCORRECT_SHRIMP.csv')
poor_t4 = pd.read_csv('/content/gdrive/MyDrive/FP_ds26Dec/dataset_28Dec (+Ha)/incorrect/INCORRECT_SIDE.csv')

poor = pd.concat([poor_t1, poor_t2, poor_t3, poor_t4])

poor.columns = ['Picture', 'Label',
                  'LEFT_SHOULDER_x','LEFT_SHOULDER_y','LEFT_SHOULDER_z',
                  'RIGHT_SHOULDER_x','RIGHT_SHOULDER_y','RIGHT_SHOULDER_z',
                  'LEFT_ELBOW_x','LEFT_ELBOW_y','LEFT_ELBOW_z',
                  'RIGHT_ELBOW_x','RIGHT_ELBOW_y','RIGHT_ELBOW_z',
                  'LEFT_WRIST_x','LEFT_WRIST_y','LEFT_WRIST_z',
                  'RIGHT_WRIST_x','RIGHT_WRIST_y','RIGHT_WRIST_z',
                  'LEFT_HIP_x','LEFT_HIP_y','LEFT_HIP_z',
                  'RIGHT_HIP_x','RIGHT_HIP_y','RIGHT_HIP_z',
                  'LEFT_KNEE_x','LEFT_KNEE_y','LEFT_KNEE_z',
                  'RIGHT_KNEE_x','RIGHT_KNEE_y','RIGHT_KNEE_z',
                  'LEFT_ANKLE_x','LEFT_ANKLE_y','LEFT_ANKLE_z',
                  'RIGHT_ANKLE_x','RIGHT_ANKLE_y','RIGHT_ANKLE_z']

print('- class GOOD :', len(good['Label']))
print('- class POOR :', len(poor['Label']))
print('- TOTAL:', len(good['Label']) + len(poor['Label']))

dataset = pd.concat([good, poor])

dataset.info()

dataset.head()

"""### Preprocessing data for training"""

ds = dataset.copy()

ds = ds.drop(columns=['Picture'])

X = ds[ds.columns[~ds.columns.isin(['Label'])]]
y = ds['Label']

# SLPIT DATASET INTO TRAIN & VALIDATION SET 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

pipeline_03 = Pipeline(steps=[('scaler', MinMaxScaler()),
                           ('estimator', RandomForestClassifier())])
pipeline_03

model_03 = pipeline_03.fit(X_train.values, y_train.values)

#Prediction, Evaluation
print('RANDOM FOREST CLASSIFICATION REPORT')
pred = model_03.predict(X_test.values)
train_pred_proba = model_03.predict_proba(X_train.values)
test_pred_proba = model_03.predict_proba(X_test.values)
print('- Log loss on train set:', log_loss(y_train.values, train_pred_proba))
print('- Log loss on test set:', log_loss(y_test.values, test_pred_proba))
print('- Acc score: ', accuracy_score(y_test.values, pred))
print('- Classification report: \n', classification_report(y_test.values, pred))

"""### Prepare 03 functions for predicting & drawing
* ```get_lmk_array```: to get array of values after extract from image
* ```predict```: prediction model
* ```draw_landmarks```: drawing landmark on prediction image
"""

# FUNCTION TO GET VALUES OF KEYPOINTS
def get_lmk_array(img_path):
    img                 = cv2.imread(img_path)
    img                 = cv2.flip(img,1)
    img_h, img_w, _     = img.shape
    img_copy            = img.copy()
    imgRGB              = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
    results             = pose.process(imgRGB)

    imp_lmk_values  = []
    if results.pose_landmarks:
        #11_LEFT_SHOULDER
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].z * img_w)
        #12_RIGHT_SHOULDER
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].z * img_w)
        #25_LEFT_ELBOW
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(13).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(13).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(13).value].z * img_w)
        #14_RIGHT_ELBOW
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(14).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(14).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(14).value].z * img_w)
        #15_LEFT_WRIST
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(15).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(15).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(15).value].z * img_w)
        #16_RIGHT_WRIST
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(16).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(16).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(16).value].z * img_w)

        #23_LEFT_HIP
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(23).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(23).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(23).value].z * img_w)
        #24_RIGHT_HIP
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(24).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(24).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(24).value].z * img_w)
        #25_LEFT_KNEE
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(25).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(25).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(25).value].z * img_w)
        #26_RIGHT_KNEE
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(26).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(26).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(26).value].z * img_w)
        #27_LEFT_ANKLE
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(27).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(27).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(27).value].z * img_w)
        #28_RIGHT_ANKLE
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(28).value].x * img_w)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(28).value].y * img_h)
        imp_lmk_values.append(results.pose_landmarks.landmark[mp_pose.PoseLandmark(28).value].z * img_w)
    
        # imp_lmk_array = list(np.array(imp_lmk_values).flatten())
        imp_lmk_array = np.array(imp_lmk_values).flatten()
        imp_lmk_array = list(imp_lmk_array)

    return imp_lmk_array

# FUNCTION TO PREDICT
def predict(model, img_path):
  img               = cv2.imread(img_path)
  img_h, img_w, _   = img.shape
  img_copy          = img.copy()
  imgRGB            = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
  results           = pose.process(imgRGB)
 
  try: 
    imp_lmk_array   = get_lmk_array(img_path)    
    X               = pd.DataFrame([imp_lmk_array])

    prediction      = model.predict(X)[0]
    pred_proba      = model.predict_proba(X)[0]
    print('X \n',X)
    print('Prediction:', prediction)
    print('Proba:', pred_proba)
  except:
    pass

# FUNCTION TO DRAW LANDMARKS
def draw_landmarks(img_path, pose, display=True):
  img               = cv2.imread(img_path)
  img_h, img_w, _   = img.shape
  output_image      = img.copy()
  imageRGB          = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)
  results           = pose.process(imageRGB)
  if results.pose_landmarks:
        mp_drawing.draw_landmarks(output_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
  if display:
      plt.figure(figsize=[15,15])
      plt.subplot(121);plt.imshow(img[:,:,::-1]); plt.title("Original Image"); plt.axis('off');
      plt.subplot(122);plt.imshow(output_image[:,:,::-1]); plt.title("Output Image"); plt.axis('off');
  else:
      return output_image

# FUNCTION TO SHOW RESULT
def result(img_path, model, pose, display=True):
  predict(model, img_path)
  draw_landmarks(img_path, pose, display=True)

"""### Prediction on image _ ALL IMG OF 2 LABELS"""

# LABEL: CORRECT
img_folder_dir = pathlib.Path('/content/gdrive/MyDrive/FP_ds26Dec/test_folder/correct')
img_paths = list(img_folder_dir.glob('*/*'))
img_paths = [str(path) for path in img_paths]
model = model_03

right =0
wrong =0
img_path_wrong =[]
for img_path in img_paths:
  if img_path.endswith('.jpg'):

    img               = cv2.imread(img_path)
    img_h, img_w, _   = img.shape
    img_copy          = img.copy()
    imgRGB            = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
    results           = pose.process(imgRGB)
    # APPEND LANDMARK VALUES
    imp_lmk_array   = get_lmk_array(img_path)    
    X               = pd.DataFrame([imp_lmk_array])
    # PREDICTION
    prediction      = model.predict(X)[0]
    pred_proba      = model.predict_proba(X)[0]
    print(img_path, '\nPrediction:', prediction, '_Proba:', pred_proba)
    # COUNT CASE RIGHT - WRONG RESULT
    if prediction == 'GOOD':
      right +=1
    else:
      wrong +=1
      img_path_wrong.append(img_path)
  if not img_path.endswith('.jpg'):
    print(img_path)
print('*' * 50)
print('REPORT TESTING _ LABEL: CORRECT', '\nTOTAL:', right+wrong,'(RIGHT-', right, 'WRONG-', wrong, ')')
print('IMG_PATH GOT WRONG PREDICTION:')
for wrong in img_path_wrong:
  print(wrong)

# Check imgages get wrong prediction 
# IMAGE 1: /content/gdrive/MyDrive/FP_ds26Dec/test_folder/correct/SIDE/Frame208.jpg
uploaded = files.upload()
for fn in uploaded.keys():
  img_path = './' + fn

predict(model_03, img_path)
draw_landmarks(img_path, pose, display=True)

# Check imgages get wrong prediction 
# IMAGE 2: /content/gdrive/MyDrive/FP_ds26Dec/test_folder/correct/SIDE/Frame208.jpg
uploaded = files.upload()
for fn in uploaded.keys():
  img_path = './' + fn

predict(model_03, img_path)
draw_landmarks(img_path, pose, display=True)

# IMG_TEST PREDICTION _ LABEL: INCORRECT

img_folder_dir = pathlib.Path('/content/gdrive/MyDrive/FP_ds26Dec/test_folder/incorrect')
img_paths = list(img_folder_dir.glob('*/*'))
img_paths = [str(path) for path in img_paths]
model = model_03

right =0
wrong =0
img_path_wrong = []
for img_path in img_paths:
  if img_path.endswith('.jpg'):
    img               = cv2.imread(img_path)
    img_h, img_w, _   = img.shape
    img_copy          = img.copy()
    imgRGB            = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
    results           = pose.process(imgRGB)
    # APPEND LANDMARK VALUES
    imp_lmk_array   = get_lmk_array(img_path)    
    X               = pd.DataFrame([imp_lmk_array])
    # PREDICTION
    prediction      = model.predict(X)[0]
    pred_proba      = model.predict_proba(X)[0]
    print(img_path, '\nPrediction:', prediction, '_Proba:', pred_proba)
    # COUNT CASE RIGHT - WRONG RESULT
    if prediction != 'GOOD':
      right +=1
    else:
      wrong +=1
      img_path_wrong.append(img_path)
 
  if not img_path.endswith('.jpg'):
    print(img_path)

print('*' * 50)
print('REPORT TESTING _ LABEL: INCORRECT', '\nTOTAL:', right+wrong,'(RIGHT-', right, 'WRONG-', wrong, ')')
print('IMG_PATH GOT WRONG PREDICTION:')
for wrong in img_path_wrong:
  print(wrong)

# Check 2-imgs get wrong prediction 
# IMAGE 1: /content/gdrive/MyDrive/FP_ds26Dec/test_folder/incorrect/SHRIMP/Frame392.jpg

uploaded = files.upload()
for fn in uploaded.keys():
  img_path = './' + fn

predict(model_03, img_path)
draw_landmarks(img_path, pose, display=True)

# Check 2-imgs get wrong prediction 
# IMAGE 2: /content/gdrive/MyDrive/FP_ds26Dec/test_folder/incorrect/LEG_POOR_T2/Frame316.jpg

uploaded = files.upload()
for fn in uploaded.keys():
  img_path = './' + fn

predict(model_03, img_path)
draw_landmarks(img_path, pose, display=True)

"""### Additional: Prediction by setting THRESHOLDING SCORE"""

'''LABEL: CORRECT'''

img_folder_dir = pathlib.Path('/content/gdrive/MyDrive/FP_ds26Dec/test_folder/correct')
img_paths = list(img_folder_dir.glob('*/*'))
img_paths = [str(path) for path in img_paths]
model = model_03

good =0; poor =0; detecting =0

for img_path in img_paths:
  if img_path.endswith('.jpg'):
    img               = cv2.imread(img_path)
    img_h, img_w, _   = img.shape
    img_copy          = img.copy()
    imgRGB            = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
    results           = pose.process(imgRGB)
    # APPEND LANDMARK VALUES
    imp_lmk_array   = get_lmk_array(img_path)    
    X               = pd.DataFrame([imp_lmk_array])
    # PREDICTION 
    prediction      = model.predict(X)[0]
    pred_proba      = model.predict_proba(X)[0]
    
    ##################################
    # RESULT BY SETTING THRESHOLDING SCORE
    if pred_proba[0] >0.6:
      print('Prediction: GOOD', '_Proba:', pred_proba)
      good +=1
    if pred_proba[0] <=0.5:
      print('Prediction: POOR', '_Proba:', pred_proba)
      print(img_path)
      poor +=1
    if pred_proba[0] >0.5 and pred_proba[0] <=0.6:
      print('Prediction: DETECTING', '_Proba:', pred_proba)
      print(img_path)
      detecting =+1
 
  if not img_path.endswith('.jpg'):
    print(img_path)
print('-' * 50)
print('REPORT TESTING _ LABEL: CORRECT','\nTOTAL:', good+poor+detecting)
print('-GOOD:', good, '\n-POOR:', poor, '\n-DETECTING:', detecting)

'''LABEL: INCORRECT'''

img_folder_dir = pathlib.Path('/content/gdrive/MyDrive/FP_ds26Dec/test_folder/incorrect')
img_paths = list(img_folder_dir.glob('*/*'))
img_paths = [str(path) for path in img_paths]
model = model_03

good =0; poor =0; detecting =0

for img_path in img_paths:
  if img_path.endswith('.jpg'):
    img               = cv2.imread(img_path)
    img_h, img_w, _   = img.shape
    img_copy          = img.copy()
    imgRGB            = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
    results           = pose.process(imgRGB)
    # APPEND LANDMARK VALUES
    imp_lmk_array   = get_lmk_array(img_path)    
    X               = pd.DataFrame([imp_lmk_array])
    # PREDICTION 
    prediction      = model.predict(X)[0]
    pred_proba      = model.predict_proba(X)[0]
    
    ##################################
    # RESULT BY SETTING THRESHOLDING SCORE
    if pred_proba[0] >0.55:
      print('Prediction: GOOD', '_Proba:', pred_proba)
      print(img_path)
      good +=1
    if pred_proba[0] <=0.5:
      print('Prediction: POOR', '_Proba:', pred_proba)
      poor +=1
    if pred_proba[0] >0.5 and pred_proba[0] <=0.55:
      print('Prediction: DETECTING', '_Proba:', pred_proba)
      print(img_path)
      detecting =+1
 
  if not img_path.endswith('.jpg'):
    print(img_path)
print('-' * 50)
print('REPORT TESTING _ LABEL: INCORRECT','\nTOTAL:', good+poor+detecting)
print('-GOOD:', good, '\n-POOR:', poor, '\n-DETECTING:', detecting)

"""### Figure out FEATURE IMPORTANCE"""

importance = pipeline_03.steps[1][1].feature_importances_

plt.figure(figsize=(20, 8))
plt.bar([x for x in range(len(importance))], importance)
plt.show()

# Get feature name of dataset >> Left wrist_y, right ankle_y
for feat, importance in zip(X_train.columns, pipeline_03.steps[1][1].feature_importances_):
    print('{f}, {i}'.format(f=feat, i=importance))

# Save model
import pickle
pickle.dump(model, open('model_28Dec.pkl', 'wb'))

"""### **DEPLOYING ON STREAMLIT**
  * ```Image```
  * ```Video uploading```
  *```Realtime via webcam``` 
###**Let's see how it works!**
"""